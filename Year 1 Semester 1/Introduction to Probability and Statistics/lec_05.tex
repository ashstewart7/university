% !TeX root = main.tex
\lecture{5}{Wed 15 Oct 2025 12:00}{Distributions}

\section{Coin Flips and Probability Recap}
Flipping a coin is one of the simplest distributions we can create.

Given a:
\begin{align*}
P(H) &= 0.5\\
P(T) &= 0.5
\end{align*}

We know that $P(HHHH) = 0.5^4$.

And $P(\text{Three Heads and One Tail}) = P(\text{HHHT or HHTH or THHH or HTHH}) = 4 \times 0.5^4$. We will take 4 coins, A, B, C, D. We denote a single result as $A_\text{Heads}$ or $C_\text{Tails}$ etc.

We can also say that the coins are independent, i.e. the probability of one result given another result is equal to just the probability of the first result:
\[
    P(A_h | B_h) = 0.5
\]

The chance of A and B being heads is:
\[
    P(A_h \text{and} B_h) = P(A_h) \times P(B_h) = P(HH)
\]

The chance of A \emph{or} B being heads is (noting \emph{or} excludes the case where both are true):
\[
    P(A_h \text{ or } B_h) = P(A_h) + P(B_h) - P(A_h \text{ and } B_h)
\]

\subsection{Discrete Distribution}
Lets consider flipping 4 coins and counting the number of heads. This forms a discrete distribution (where only 5 possible values are possible, 0, 1, 2, 3, 4). This distribution must be normalised (sum to 1), so:
\[
    \sum_r P(r) = 1
\]

We can also consider the mean (expected) number of heads:
\[
    \langle r\rangle = \sum_{r} r P(r)
\]

This function, $P(x)$ is called a \emph{probability mass function}, and the sum of all values must be 1.

\subsection{Continuous Distributions}
Continuous distributions have similar conditions:
\[
    \int_{-\infty}^{\infty} P(x) dx =1
\]

\[
    \langle x\rangle = \int_{-\infty}^{\infty} xP(x) \, dx
\]

And for the probability of the result lying between a and b:

\[
    \int_{a}^{b} P(x) \, dx
\]

We cannot, in a continuous distribution consider the probability of an exact result, i.e. $P(x = a)$, $a \in \R$. As there are infinitely many possible values, the probability of any precise one is not meaningful (always zero). We therefore must always consider the probability of the result lying in some non-zero range. 

P(x) in this case is called a \emph{probability density function} and the area under the PDF curve must sum to zero. Note that this means that P(x) at any point may exceed one, so long as the overall area is equal to 1.

\section{Binomial Distribution}

\section{Normal Distribution}

\section{Poisson Distribution}

